import json
import sys
import os
import time
import random
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from datetime import datetime

# ======================================================
# C·∫§U H√åNH
# ======================================================
SPREADSHEET_ID = '1YqO4MVEzAz61jc_WCVSS00LpRlrDb5r0LnuzNi6BYUY'
MASTER_SHEET_NAME = 'Sheet1' 
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]

def get_driver():
    """C·∫•u h√¨nh Chrome"""
    chrome_options = Options()
    chrome_options.add_argument("--headless=new") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled") 
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    prefs = {"profile.managed_default_content_settings.images": 2, "profile.managed_default_content_settings.stylesheets": 2}
    chrome_options.add_experimental_option("prefs", prefs)
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=chrome_options)

def scrape_product_logic(driver, wait, product):
    """
    H√†m t√¨m gi√° th√¥ng minh: ƒê√£ n√¢ng c·∫•p t·ª´ logic c·ªßa b·∫°n.
    Th√™m 'wait' ƒë·ªÉ x·ª≠ l√Ω web load ch·∫≠m.
    """
    selectors_to_try = []

    # 1. X·ª≠ l√Ω th√¥ng minh file JSON (ch·∫•p nh·∫≠n c·∫£ 'selectors' list v√† 'selector' string)
    # ∆Øu ti√™n key 'selectors' (d·∫°ng list)
    if 'selectors' in product and isinstance(product['selectors'], list):
        selectors_to_try.extend(product['selectors'])
    
    # Fallback: Key 'selector' (d·∫°ng string ho·∫∑c list c≈©)
    elif 'selector' in product:
        if isinstance(product['selector'], list):
            selectors_to_try.extend(product['selector'])
        else:
            selectors_to_try.append(product['selector'])

    # N·∫øu kh√¥ng c√≥ selector n√†o
    if not selectors_to_try:
        return "0", "No Selector"

    # 2. Th·ª≠ t·ª´ng c√°i m·ªôt
    for i, sel in enumerate(selectors_to_try):
        try:
            # T·ª± ƒë·ªông nh·∫≠n di·ªán XPath/CSS
            sel = str(sel).strip()
            if sel.startswith('/') or sel.startswith('(') or sel.startswith('..'):
                by_type = By.XPATH
            else:
                by_type = By.CSS_SELECTOR
            
            # --- KH√ÅC BI·ªÜT QUAN TR·ªåNG: D√πng Wait thay v√¨ find_element ---
            # Ch·ªù t·ªëi ƒëa 3 gi√¢y cho m·ªói selector
            element = wait.until(EC.presence_of_element_located((by_type, sel)))
            
            # Scroll nh·∫π ƒë·ªÉ ƒë·∫£m b·∫£o element ƒë∆∞·ª£c render (quan tr·ªçng v·ªõi Shopee/Lazada)
            driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)

            raw_text = element.text
            # L·ªçc l·∫•y s·ªë (Logic c·ªßa b·∫°n)
            clean_price = ''.join(filter(str.isdigit, raw_text))
            
            # Ki·ªÉm tra gi√° tr·ªã h·ª£p l·ªá
            if clean_price and int(clean_price) > 0:
                print(f"   ‚úÖ OK t·∫°i selector #{i+1}: {clean_price}")
                return clean_price, "OK"
                
        except Exception:
            # Th·ª≠ c√°i ti·∫øp theo
            continue
            
    # Th·ª≠ h·∫øt m√† v·∫´n tr∆∞·ª£t
    return "0", "Fail"

def scrape_data(config_path):
    dealer_name = os.path.basename(config_path).replace('.json', '').upper()
    with open(config_path, 'r', encoding='utf-8') as f:
        products = json.load(f)

    driver = get_driver()
    # T·∫°o bi·∫øn wait d√πng chung, timeout 3s m·ªói l·∫ßn th·ª≠
    wait = WebDriverWait(driver, 3) 
    results = []
    
    print(f"[{dealer_name}] B·∫Øt ƒë·∫ßu qu√©t {len(products)} s·∫£n ph·∫©m...")

    for product in products:
        current_time = datetime.now()
        
        # G·ªçi h√†m logic ri√™ng ƒë√£ t√°ch ra
        try:
            driver.get(product['url'])
            price, status = scrape_product_logic(driver, wait, product)
        except Exception as e:
            print(f"   ‚ò†Ô∏è L·ªói t·∫£i trang: {str(e)[:50]}")
            price, status = "0", "ErrLoad"

        # N·∫øu Fail, in ra ƒë·ªÉ debug
        if status == "Fail":
            print(f"   ‚ùå {product['name']}: Kh√¥ng t√¨m th·∫•y gi√° (ƒê√£ th·ª≠ h·∫øt selector)")

        row = [
            current_time.strftime("%d/%m/%Y"),
            current_time.strftime("%H:%M:%S"),
            dealer_name,
            product['name'],
            price,
            status,
            product['url']
        ]
        results.append(row)

    driver.quit()
    return results

def save_to_master_sheet(data, max_retries=10):
    if not data: return
    creds = ServiceAccountCredentials.from_json_keyfile_name('service_account.json', scope)
    client = gspread.authorize(creds)
    
    for attempt in range(max_retries):
        try:
            sheet = client.open_by_key(SPREADSHEET_ID)
            try:
                worksheet = sheet.worksheet(MASTER_SHEET_NAME)
            except:
                worksheet = sheet.add_worksheet(title=MASTER_SHEET_NAME, rows=2000, cols=10)
                worksheet.append_row(["Ng√†y", "Th·ªùi gian", "ƒê·∫°i l√Ω", "S·∫£n ph·∫©m", "Gi√°", "Tr·∫°ng th√°i", "Link"])

            time.sleep(random.uniform(1, 3))
            worksheet.append_rows(data)
            print(f"üíæ ƒê√£ ghi {len(data)} d√≤ng v√†o Sheet!")
            return 
        except Exception as e:
            time.sleep(5)
    print("‚ùå L·ªói ghi Sheet.")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("C√°ch d√πng: python bot.py <config.json>")
        sys.exit(1)
    scrape_data(sys.argv[1])
    save_to_master_sheet(scrape_data(sys.argv[1]))
